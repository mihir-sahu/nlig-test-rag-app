"""
test-rag-app - RAG Application
Main FastAPI application entry point
"""
from fastapi import FastAPI, File, UploadFile, HTTPException, status
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import logging

from app.config import settings
from app.models import QueryRequest, QueryResponse, IngestResponse
from app.ingest import ingest_document
from app.chain import rag_chain, rag_chain_stream

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="test-rag-app",
    description="RAG Application - Retrieval Augmented Generation with LangChain",
    version="1.0.0"
)

# CORS configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "app": "test-rag-app",
        "version": "1.0.0"
    }


@app.get("/health")
async def health():
    """Detailed health check"""
    return {
        "status": "healthy",
        "vector_db": "connected",
        "llm_provider": "openai",
        "model": "gpt-4o-mini"
    }


@app.post("/ingest", response_model=IngestResponse)
async def ingest(file: UploadFile = File(...)):
    """
    Ingest a document into the vector database
    
    Supported formats: PDF, TXT, MD, DOCX
    """
    try:
        logger.info(f"Ingesting document: {file.filename}")
        
        # Read file content
        content = await file.read()
        
        # Process document
        result = await ingest_document(
            content=content,
            filename=file.filename,
            content_type=file.content_type
        )
        
        logger.info(f"Successfully ingested {result['chunks_created']} chunks")
        
        return IngestResponse(
            filename=file.filename,
            chunks_created=result['chunks_created'],
            status="success",
            message=f"Document ingested successfully"
        )
        
    except Exception as e:
        logger.error(f"Error ingesting document: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to ingest document: {str(e)}"
        )


@app.post("/query", response_model=QueryResponse)
async def query(request: QueryRequest):
    """
    Query the RAG system
    
    Returns a response based on retrieved context from ingested documents
    """
    try:
        logger.info(f"Processing query: {request.query}")
        
        # Execute RAG chain
        response = await rag_chain(
            query=request.query,
            top_k=request.top_k or settings.TOP_K
        )
        
        return QueryResponse(
            query=request.query,
            answer=response['answer'],
            sources=response['sources'],
            context_chunks=response['context_chunks']
        )
        
    except Exception as e:
        logger.error(f"Error processing query: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to process query: {str(e)}"
        )


@app.post("/query/stream")
async def query_stream(request: QueryRequest):
    """
    Query the RAG system with streaming response
    
    Returns server-sent events (SSE) stream
    """
    try:
        logger.info(f"Processing streaming query: {request.query}")
        
        async def generate():
            async for chunk in rag_chain_stream(
                query=request.query,
                top_k=request.top_k or settings.TOP_K
            ):
                yield f"data: {chunk}\n\n"
        
        return StreamingResponse(
            generate(),
            media_type="text/event-stream"
        )
        
    except Exception as e:
        logger.error(f"Error processing streaming query: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to process streaming query: {str(e)}"
        )


@app.get("/metrics")
async def metrics():
    """Prometheus metrics endpoint"""
    # TODO: Implement Prometheus metrics
    return {"metrics": "not_implemented"}


if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.DEBUG
    )
